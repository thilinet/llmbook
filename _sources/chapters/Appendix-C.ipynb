{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab40b6b3-5e27-4c46-848c-b78f3bb98e86",
   "metadata": {},
   "source": [
    "# Torch matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a01a96ce-6514-4894-b3e6-202a35ecf711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.6104,  0.5499,  0.3142],\n",
       "        [-8.3252, -0.6339, -1.1291]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\"\"\"\n",
    "torch.mm - performs a matrix multiplication without broadcasting\n",
    "It expects two 2D tensors so n × m * m × p = n×p\n",
    "i.e. only for matrices and not higher dimensional tensors.\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.mm.html:\n",
    "\"\"\"\n",
    "\n",
    "a = torch.randn(2,5)\n",
    "b = torch.randn(3,5)\n",
    "\n",
    "torch.mm(a,b.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43254515-b32f-4c15-afd6-0573cfc19481",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mtorch.mul - performs a elementwise multiplication with broadcasting - (Tensor) by (Tensor or Number)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mtorch.mul does not perform a matrix multiplication. It broadcasts two tensors and performs an elementwise multiplication. \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mhttps://pytorch.org/docs/stable/generated/torch.mul.html\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "torch.mul - performs a elementwise multiplication with broadcasting - (Tensor) by (Tensor or Number)\n",
    "torch.mul does not perform a matrix multiplication. It broadcasts two tensors and performs \n",
    "an elementwise multiplication. \n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.mul.html\n",
    "\"\"\"\n",
    "\n",
    "torch.mul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b99f26c-25ab-4053-a372-4e43e048c214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0039,  0.9935,  0.0681,  0.0039,  0.8029],\n",
       "        [-1.0538, -0.4971, -2.3967,  1.0259,  0.3220]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2,5)\n",
    "b = torch.randn(2,5)\n",
    "\n",
    "torch.mul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee176f4d-8bf4-4094-a98e-2117b5e6465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    torch.matmul\n",
    "\n",
    "It is better to check out the official documentation https://pytorch.org/docs/stable/generated/torch.matmul.html as it uses different modes depending on the input tensors. It may perform dot product, matrix-matrix product or batched matrix products with broadcasting.\n",
    "\n",
    "As for your question regarding product of:\n",
    "\n",
    "tensor1 = torch.randn(10, 3, 4)\n",
    "tensor2 = torch.randn(4)\n",
    "\n",
    "it is a batched version of a product. please check this simple example for understanding:\n",
    "\n",
    "import torch\n",
    "\n",
    "# 3x1x3\n",
    "a = torch.FloatTensor([[[1, 2, 3]], [[3, 4, 5]], [[6, 7, 8]]])\n",
    "# 3\n",
    "b = torch.FloatTensor([1, 10, 100])\n",
    "r1 = torch.matmul(a, b)\n",
    "\n",
    "r2 = torch.stack((\n",
    "    torch.matmul(a[0], b),\n",
    "    torch.matmul(a[1], b),\n",
    "    torch.matmul(a[2], b),\n",
    "))\n",
    "assert torch.allclose(r1, r2)\n",
    "\n",
    "So it can be seen as a multiple operations stacked together across batch dimension.\n",
    "\n",
    "Also it may be useful to read about broadcasting:\n",
    "\n",
    "https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ea01a-aa80-48eb-8277-e4d64f334f93",
   "metadata": {},
   "outputs": [],
   "source": [
    " want to add the introduction of torch.bmm, which is batch matrix-matrix product.\n",
    "\n",
    "torch.bmm(input,mat2,*,out=None)→Tensor\n",
    "\n",
    "shape: (b×n×m),(b×m×p) -->(b×n×p)\n",
    "\n",
    "Performs a batch matrix-matrix product of matrices stored in input and mat2. input and mat2 must be 3-D tensors each containing the same number of matrices.\n",
    "\n",
    "This function does not broadcast.\n",
    "\n",
    "Example\n",
    "\n",
    "input = torch.randn(10, 3, 4)\n",
    "mat2 = torch.randn(10, 4, 5)\n",
    "res = torch.bmm(input, mat2)\n",
    "res.size()  # torch.Size([10, 3, 5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
