{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71d2d3f9-17e3-4bec-a287-9126047a3cbe",
   "metadata": {},
   "source": [
    "# Chapter 4 - Fine tuning a LLM\n",
    "\n",
    "\n",
    "\n",
    "Vision models popularized transfer learning. Transfer learning is taking an pre-trained model and training on it to perform new tasks. I hope its not blashphemy to say Fine tuning is the new name for transfer learning in LLM world. We will look into fine tuning an existing large language model in this chapter. For those from vision domain, will relate to freezing some layers in the source model and then perform transfer learning. The weights of the frozen layers are untouched, only those layers left unfrozen are modified. In some cases of transfer learning new layers are added to the existing layers are those are trained. Most of those concepts apply to fine tuning LLMs.\n",
    "\n",
    "LLMs pre-trained on large corpus exibit in-context learning capability. Models like GPT-4, Gemini can perform new task on which it was not previous trained.By providing a prompt which comprises of few examples of the target task, these LLMs should perform the required job. We will see more about in-context learning in a later chapter.\n",
    "\n",
    "So when do we fine tune? Say you are building a document summarization application for your domain. Your compnay does not have enough budget to purchase copilot or openai's API to access a high performance large language model. You end up picking a small language model (unlucky you, your company denies additional infrastructure, no 8 GPU machines for you to host your model). You try your hands with prompt engineering this small language model hoping to leverage incontext learning ability. No luck. Fine tuning is the answer in these scenario.\n",
    "\n",
    "In full fine tuning, we allow the training to modify all weights in all the layers of the original model. This is very similar to our pre-training in last chapter, expect we do a full training for very small number of epochs using the new dataset. We will be introducing the transformers library from HuggingFace. For training, again we use the Trainer API from HuggingFace. HuggingFace is one of the fastest growing LLM ecosystem. They have most of the open source models and everyday contributors are adding newer models. As an LLM developer we believe HuggingFace transformers will be a good tool in your toolbox. Recently hugging face released a small LLM model SmoLLM trained completely on synthetic data. We train this model on Fyodor Dostoveskeys' The Brothers Karmazov novel.\n",
    "\n",
    "Text classification systems are ubiquotous now. LLMs can be fine tuned to perform text classification tasks. The output of the\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1f00d6",
   "metadata": {},
   "source": [
    "## Full fine tune\n",
    "\n",
    "In this section, we will load a HuggingFace Model and do a complete finetuning with a text datasource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54040387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "current_path = Path(os.getcwd())\n",
    "save_directory = str(Path(current_path.parent.parent.absolute(), \"bin\",\"chapter4\",\"fullfinetune\"))\n",
    "data_directory = str(Path(current_path.parent.parent.absolute(), \"data\", \"chapter4\"))\n",
    "data_file_name = \"brothers.txt\"\n",
    "data_file_path = Path(data_directory, data_file_name)\n",
    "parent_path  = str(current_path.parent.absolute())\n",
    "\n",
    "sys.path.append(parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "319bc5ee-8755-4685-8b15-b38101d98e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gopi/Documents/small_llm/llmbook/data/chapter4/brothers.txt already exists. Skip Download\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer, Trainer, TrainingArguments\n",
    "from transformers import AutoModelForCausalLM, DataCollatorForLanguageModeling\n",
    "import urllib.request\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "model_path = \"HuggingFaceTB/SmolLM-135M\"\n",
    "train_source_uri = \"https://www.gutenberg.org/cache/epub/28054/pg28054.txt\"\n",
    "\n",
    "if not data_file_path.exists():\n",
    "    print(f\"Download {train_source_uri} to {str(data_file_path)}\")\n",
    "    with urllib.request.urlopen(train_source_uri) as response:\n",
    "        with open(str(data_file_path), \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "else:\n",
    "    print(f\"{str(data_file_path)} already exists. Skip Download\")\n",
    "    \n",
    "            \n",
    "dataset = load_dataset(\"text\", data_files=str(data_file_path))\n",
    "\n",
    "# Tokenizer and data loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec632668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gopi/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(str(batch))\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer,mlm =False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2914f367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gopi/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'third son of Fyodor Pavlovitch Karamazov is the most famous of all the princes of Russia. He was born in 1765 in the village of Kostroma, in what is now the Russian Federation. His father, Ivan Pavlovich, was a military officer and a member of the Imperial Guard. Ivan was also a great-grandson of Ivan the Terrible, the last tsar of Muscovy.\\nKaramuzov was'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "\n",
    "start_context = \"third son of Fyodor Pavlovitch Karamazov is\"\n",
    "prompt_tokens = tokenizer(start_context, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "output = model.generate(\n",
    "    input_ids = prompt_tokens[\"input_ids\"]\n",
    "   ,max_length=100\n",
    "   ,num_beams=2\n",
    "   ,temperature=0.7\n",
    "   ,top_k=50\n",
    "   ,top_p=0.9\n",
    "   ,no_repeat_ngram_size=2\n",
    "\n",
    ")\n",
    "\n",
    "tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79403627",
   "metadata": {},
   "source": [
    "## Full fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f8553d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2353' max='2353' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2353/2353 16:21, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.057900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.892200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.871000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.835400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'Trainer' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_58911/3686729478.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Trainer' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "\n",
    "train_args = TrainingArguments(\n",
    "    output_dir = save_directory\n",
    "   ,num_train_epochs = 1\n",
    "   ,per_device_train_batch_size=16\n",
    "   ,save_steps=500\n",
    "   ,save_total_limit=2\n",
    "   ,report_to=\"none\" \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model\n",
    "   ,args =train_args\n",
    "   ,data_collator=data_collator\n",
    "   ,train_dataset=tokenized_dataset[\"train\"]\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a6dd145",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7571b3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = AutoModelForCausalLM.from_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5326c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gopi/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'third son of Fyodor Pavlovitch Karamazov is the only one to have been married to a Russian woman. The other two are the daughters of Ivan Pavlovich and Alyosha, who were married at the age of twenty-five. Ivanâ€™s wife died in 1880, and the other was a widow. She was the daughter of a merchant, a man who had married a woman of the highest rank. He had been a captain in the'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_context = \"third son of Fyodor Pavlovitch Karamazov is\"\n",
    "prompt_tokens = tokenizer(start_context, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "output = new_model.generate(\n",
    "    input_ids = prompt_tokens[\"input_ids\"]\n",
    "   ,max_length=100\n",
    "   ,num_beams=2\n",
    "   ,temperature=0.7\n",
    "   ,top_k=50\n",
    "   ,top_p=0.9\n",
    "   ,no_repeat_ngram_size=2\n",
    "\n",
    ")\n",
    "\n",
    "tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e9eca05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14370,  4132,   282,   426,   105, 29672, 29396, 34331,  3224, 13463,\n",
       "           332,  1437,   749,   314]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_tokens[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f212d6",
   "metadata": {},
   "source": [
    "## Freezing certain layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b837ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight True\n",
      "model.layers.0.self_attn.q_proj.weight True\n",
      "model.layers.0.self_attn.k_proj.weight True\n",
      "model.layers.0.self_attn.v_proj.weight True\n",
      "model.layers.0.self_attn.o_proj.weight True\n",
      "model.layers.0.mlp.gate_proj.weight True\n",
      "model.layers.0.mlp.up_proj.weight True\n",
      "model.layers.0.mlp.down_proj.weight True\n",
      "model.layers.0.input_layernorm.weight True\n",
      "model.layers.0.post_attention_layernorm.weight True\n",
      "model.layers.1.self_attn.q_proj.weight True\n",
      "model.layers.1.self_attn.k_proj.weight True\n",
      "model.layers.1.self_attn.v_proj.weight True\n",
      "model.layers.1.self_attn.o_proj.weight True\n",
      "model.layers.1.mlp.gate_proj.weight True\n",
      "model.layers.1.mlp.up_proj.weight True\n",
      "model.layers.1.mlp.down_proj.weight True\n",
      "model.layers.1.input_layernorm.weight True\n",
      "model.layers.1.post_attention_layernorm.weight True\n",
      "model.layers.2.self_attn.q_proj.weight True\n",
      "model.layers.2.self_attn.k_proj.weight True\n",
      "model.layers.2.self_attn.v_proj.weight True\n",
      "model.layers.2.self_attn.o_proj.weight True\n",
      "model.layers.2.mlp.gate_proj.weight True\n",
      "model.layers.2.mlp.up_proj.weight True\n",
      "model.layers.2.mlp.down_proj.weight True\n",
      "model.layers.2.input_layernorm.weight True\n",
      "model.layers.2.post_attention_layernorm.weight True\n",
      "model.layers.3.self_attn.q_proj.weight True\n",
      "model.layers.3.self_attn.k_proj.weight True\n",
      "model.layers.3.self_attn.v_proj.weight True\n",
      "model.layers.3.self_attn.o_proj.weight True\n",
      "model.layers.3.mlp.gate_proj.weight True\n",
      "model.layers.3.mlp.up_proj.weight True\n",
      "model.layers.3.mlp.down_proj.weight True\n",
      "model.layers.3.input_layernorm.weight True\n",
      "model.layers.3.post_attention_layernorm.weight True\n",
      "model.layers.4.self_attn.q_proj.weight True\n",
      "model.layers.4.self_attn.k_proj.weight True\n",
      "model.layers.4.self_attn.v_proj.weight True\n",
      "model.layers.4.self_attn.o_proj.weight True\n",
      "model.layers.4.mlp.gate_proj.weight True\n",
      "model.layers.4.mlp.up_proj.weight True\n",
      "model.layers.4.mlp.down_proj.weight True\n",
      "model.layers.4.input_layernorm.weight True\n",
      "model.layers.4.post_attention_layernorm.weight True\n",
      "model.layers.5.self_attn.q_proj.weight True\n",
      "model.layers.5.self_attn.k_proj.weight True\n",
      "model.layers.5.self_attn.v_proj.weight True\n",
      "model.layers.5.self_attn.o_proj.weight True\n",
      "model.layers.5.mlp.gate_proj.weight True\n",
      "model.layers.5.mlp.up_proj.weight True\n",
      "model.layers.5.mlp.down_proj.weight True\n",
      "model.layers.5.input_layernorm.weight True\n",
      "model.layers.5.post_attention_layernorm.weight True\n",
      "model.layers.6.self_attn.q_proj.weight True\n",
      "model.layers.6.self_attn.k_proj.weight True\n",
      "model.layers.6.self_attn.v_proj.weight True\n",
      "model.layers.6.self_attn.o_proj.weight True\n",
      "model.layers.6.mlp.gate_proj.weight True\n",
      "model.layers.6.mlp.up_proj.weight True\n",
      "model.layers.6.mlp.down_proj.weight True\n",
      "model.layers.6.input_layernorm.weight True\n",
      "model.layers.6.post_attention_layernorm.weight True\n",
      "model.layers.7.self_attn.q_proj.weight True\n",
      "model.layers.7.self_attn.k_proj.weight True\n",
      "model.layers.7.self_attn.v_proj.weight True\n",
      "model.layers.7.self_attn.o_proj.weight True\n",
      "model.layers.7.mlp.gate_proj.weight True\n",
      "model.layers.7.mlp.up_proj.weight True\n",
      "model.layers.7.mlp.down_proj.weight True\n",
      "model.layers.7.input_layernorm.weight True\n",
      "model.layers.7.post_attention_layernorm.weight True\n",
      "model.layers.8.self_attn.q_proj.weight True\n",
      "model.layers.8.self_attn.k_proj.weight True\n",
      "model.layers.8.self_attn.v_proj.weight True\n",
      "model.layers.8.self_attn.o_proj.weight True\n",
      "model.layers.8.mlp.gate_proj.weight True\n",
      "model.layers.8.mlp.up_proj.weight True\n",
      "model.layers.8.mlp.down_proj.weight True\n",
      "model.layers.8.input_layernorm.weight True\n",
      "model.layers.8.post_attention_layernorm.weight True\n",
      "model.layers.9.self_attn.q_proj.weight True\n",
      "model.layers.9.self_attn.k_proj.weight True\n",
      "model.layers.9.self_attn.v_proj.weight True\n",
      "model.layers.9.self_attn.o_proj.weight True\n",
      "model.layers.9.mlp.gate_proj.weight True\n",
      "model.layers.9.mlp.up_proj.weight True\n",
      "model.layers.9.mlp.down_proj.weight True\n",
      "model.layers.9.input_layernorm.weight True\n",
      "model.layers.9.post_attention_layernorm.weight True\n",
      "model.layers.10.self_attn.q_proj.weight True\n",
      "model.layers.10.self_attn.k_proj.weight True\n",
      "model.layers.10.self_attn.v_proj.weight True\n",
      "model.layers.10.self_attn.o_proj.weight True\n",
      "model.layers.10.mlp.gate_proj.weight True\n",
      "model.layers.10.mlp.up_proj.weight True\n",
      "model.layers.10.mlp.down_proj.weight True\n",
      "model.layers.10.input_layernorm.weight True\n",
      "model.layers.10.post_attention_layernorm.weight True\n",
      "model.layers.11.self_attn.q_proj.weight True\n",
      "model.layers.11.self_attn.k_proj.weight True\n",
      "model.layers.11.self_attn.v_proj.weight True\n",
      "model.layers.11.self_attn.o_proj.weight True\n",
      "model.layers.11.mlp.gate_proj.weight True\n",
      "model.layers.11.mlp.up_proj.weight True\n",
      "model.layers.11.mlp.down_proj.weight True\n",
      "model.layers.11.input_layernorm.weight True\n",
      "model.layers.11.post_attention_layernorm.weight True\n",
      "model.layers.12.self_attn.q_proj.weight True\n",
      "model.layers.12.self_attn.k_proj.weight True\n",
      "model.layers.12.self_attn.v_proj.weight True\n",
      "model.layers.12.self_attn.o_proj.weight True\n",
      "model.layers.12.mlp.gate_proj.weight True\n",
      "model.layers.12.mlp.up_proj.weight True\n",
      "model.layers.12.mlp.down_proj.weight True\n",
      "model.layers.12.input_layernorm.weight True\n",
      "model.layers.12.post_attention_layernorm.weight True\n",
      "model.layers.13.self_attn.q_proj.weight True\n",
      "model.layers.13.self_attn.k_proj.weight True\n",
      "model.layers.13.self_attn.v_proj.weight True\n",
      "model.layers.13.self_attn.o_proj.weight True\n",
      "model.layers.13.mlp.gate_proj.weight True\n",
      "model.layers.13.mlp.up_proj.weight True\n",
      "model.layers.13.mlp.down_proj.weight True\n",
      "model.layers.13.input_layernorm.weight True\n",
      "model.layers.13.post_attention_layernorm.weight True\n",
      "model.layers.14.self_attn.q_proj.weight True\n",
      "model.layers.14.self_attn.k_proj.weight True\n",
      "model.layers.14.self_attn.v_proj.weight True\n",
      "model.layers.14.self_attn.o_proj.weight True\n",
      "model.layers.14.mlp.gate_proj.weight True\n",
      "model.layers.14.mlp.up_proj.weight True\n",
      "model.layers.14.mlp.down_proj.weight True\n",
      "model.layers.14.input_layernorm.weight True\n",
      "model.layers.14.post_attention_layernorm.weight True\n",
      "model.layers.15.self_attn.q_proj.weight True\n",
      "model.layers.15.self_attn.k_proj.weight True\n",
      "model.layers.15.self_attn.v_proj.weight True\n",
      "model.layers.15.self_attn.o_proj.weight True\n",
      "model.layers.15.mlp.gate_proj.weight True\n",
      "model.layers.15.mlp.up_proj.weight True\n",
      "model.layers.15.mlp.down_proj.weight True\n",
      "model.layers.15.input_layernorm.weight True\n",
      "model.layers.15.post_attention_layernorm.weight True\n",
      "model.layers.16.self_attn.q_proj.weight True\n",
      "model.layers.16.self_attn.k_proj.weight True\n",
      "model.layers.16.self_attn.v_proj.weight True\n",
      "model.layers.16.self_attn.o_proj.weight True\n",
      "model.layers.16.mlp.gate_proj.weight True\n",
      "model.layers.16.mlp.up_proj.weight True\n",
      "model.layers.16.mlp.down_proj.weight True\n",
      "model.layers.16.input_layernorm.weight True\n",
      "model.layers.16.post_attention_layernorm.weight True\n",
      "model.layers.17.self_attn.q_proj.weight True\n",
      "model.layers.17.self_attn.k_proj.weight True\n",
      "model.layers.17.self_attn.v_proj.weight True\n",
      "model.layers.17.self_attn.o_proj.weight True\n",
      "model.layers.17.mlp.gate_proj.weight True\n",
      "model.layers.17.mlp.up_proj.weight True\n",
      "model.layers.17.mlp.down_proj.weight True\n",
      "model.layers.17.input_layernorm.weight True\n",
      "model.layers.17.post_attention_layernorm.weight True\n",
      "model.layers.18.self_attn.q_proj.weight True\n",
      "model.layers.18.self_attn.k_proj.weight True\n",
      "model.layers.18.self_attn.v_proj.weight True\n",
      "model.layers.18.self_attn.o_proj.weight True\n",
      "model.layers.18.mlp.gate_proj.weight True\n",
      "model.layers.18.mlp.up_proj.weight True\n",
      "model.layers.18.mlp.down_proj.weight True\n",
      "model.layers.18.input_layernorm.weight True\n",
      "model.layers.18.post_attention_layernorm.weight True\n",
      "model.layers.19.self_attn.q_proj.weight True\n",
      "model.layers.19.self_attn.k_proj.weight True\n",
      "model.layers.19.self_attn.v_proj.weight True\n",
      "model.layers.19.self_attn.o_proj.weight True\n",
      "model.layers.19.mlp.gate_proj.weight True\n",
      "model.layers.19.mlp.up_proj.weight True\n",
      "model.layers.19.mlp.down_proj.weight True\n",
      "model.layers.19.input_layernorm.weight True\n",
      "model.layers.19.post_attention_layernorm.weight True\n",
      "model.layers.20.self_attn.q_proj.weight True\n",
      "model.layers.20.self_attn.k_proj.weight True\n",
      "model.layers.20.self_attn.v_proj.weight True\n",
      "model.layers.20.self_attn.o_proj.weight True\n",
      "model.layers.20.mlp.gate_proj.weight True\n",
      "model.layers.20.mlp.up_proj.weight True\n",
      "model.layers.20.mlp.down_proj.weight True\n",
      "model.layers.20.input_layernorm.weight True\n",
      "model.layers.20.post_attention_layernorm.weight True\n",
      "model.layers.21.self_attn.q_proj.weight True\n",
      "model.layers.21.self_attn.k_proj.weight True\n",
      "model.layers.21.self_attn.v_proj.weight True\n",
      "model.layers.21.self_attn.o_proj.weight True\n",
      "model.layers.21.mlp.gate_proj.weight True\n",
      "model.layers.21.mlp.up_proj.weight True\n",
      "model.layers.21.mlp.down_proj.weight True\n",
      "model.layers.21.input_layernorm.weight True\n",
      "model.layers.21.post_attention_layernorm.weight True\n",
      "model.layers.22.self_attn.q_proj.weight True\n",
      "model.layers.22.self_attn.k_proj.weight True\n",
      "model.layers.22.self_attn.v_proj.weight True\n",
      "model.layers.22.self_attn.o_proj.weight True\n",
      "model.layers.22.mlp.gate_proj.weight True\n",
      "model.layers.22.mlp.up_proj.weight True\n",
      "model.layers.22.mlp.down_proj.weight True\n",
      "model.layers.22.input_layernorm.weight True\n",
      "model.layers.22.post_attention_layernorm.weight True\n",
      "model.layers.23.self_attn.q_proj.weight True\n",
      "model.layers.23.self_attn.k_proj.weight True\n",
      "model.layers.23.self_attn.v_proj.weight True\n",
      "model.layers.23.self_attn.o_proj.weight True\n",
      "model.layers.23.mlp.gate_proj.weight True\n",
      "model.layers.23.mlp.up_proj.weight True\n",
      "model.layers.23.mlp.down_proj.weight True\n",
      "model.layers.23.input_layernorm.weight True\n",
      "model.layers.23.post_attention_layernorm.weight True\n",
      "model.layers.24.self_attn.q_proj.weight True\n",
      "model.layers.24.self_attn.k_proj.weight True\n",
      "model.layers.24.self_attn.v_proj.weight True\n",
      "model.layers.24.self_attn.o_proj.weight True\n",
      "model.layers.24.mlp.gate_proj.weight True\n",
      "model.layers.24.mlp.up_proj.weight True\n",
      "model.layers.24.mlp.down_proj.weight True\n",
      "model.layers.24.input_layernorm.weight True\n",
      "model.layers.24.post_attention_layernorm.weight True\n",
      "model.layers.25.self_attn.q_proj.weight True\n",
      "model.layers.25.self_attn.k_proj.weight True\n",
      "model.layers.25.self_attn.v_proj.weight True\n",
      "model.layers.25.self_attn.o_proj.weight True\n",
      "model.layers.25.mlp.gate_proj.weight True\n",
      "model.layers.25.mlp.up_proj.weight True\n",
      "model.layers.25.mlp.down_proj.weight True\n",
      "model.layers.25.input_layernorm.weight True\n",
      "model.layers.25.post_attention_layernorm.weight True\n",
      "model.layers.26.self_attn.q_proj.weight True\n",
      "model.layers.26.self_attn.k_proj.weight True\n",
      "model.layers.26.self_attn.v_proj.weight True\n",
      "model.layers.26.self_attn.o_proj.weight True\n",
      "model.layers.26.mlp.gate_proj.weight True\n",
      "model.layers.26.mlp.up_proj.weight True\n",
      "model.layers.26.mlp.down_proj.weight True\n",
      "model.layers.26.input_layernorm.weight True\n",
      "model.layers.26.post_attention_layernorm.weight True\n",
      "model.layers.27.self_attn.q_proj.weight True\n",
      "model.layers.27.self_attn.k_proj.weight True\n",
      "model.layers.27.self_attn.v_proj.weight True\n",
      "model.layers.27.self_attn.o_proj.weight True\n",
      "model.layers.27.mlp.gate_proj.weight True\n",
      "model.layers.27.mlp.up_proj.weight True\n",
      "model.layers.27.mlp.down_proj.weight True\n",
      "model.layers.27.input_layernorm.weight True\n",
      "model.layers.27.post_attention_layernorm.weight True\n",
      "model.layers.28.self_attn.q_proj.weight True\n",
      "model.layers.28.self_attn.k_proj.weight True\n",
      "model.layers.28.self_attn.v_proj.weight True\n",
      "model.layers.28.self_attn.o_proj.weight True\n",
      "model.layers.28.mlp.gate_proj.weight True\n",
      "model.layers.28.mlp.up_proj.weight True\n",
      "model.layers.28.mlp.down_proj.weight True\n",
      "model.layers.28.input_layernorm.weight True\n",
      "model.layers.28.post_attention_layernorm.weight True\n",
      "model.layers.29.self_attn.q_proj.weight True\n",
      "model.layers.29.self_attn.k_proj.weight True\n",
      "model.layers.29.self_attn.v_proj.weight True\n",
      "model.layers.29.self_attn.o_proj.weight True\n",
      "model.layers.29.mlp.gate_proj.weight True\n",
      "model.layers.29.mlp.up_proj.weight True\n",
      "model.layers.29.mlp.down_proj.weight True\n",
      "model.layers.29.input_layernorm.weight True\n",
      "model.layers.29.post_attention_layernorm.weight True\n",
      "model.norm.weight True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "     print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab68cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decd1516",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task based Fine Tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
