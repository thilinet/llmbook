{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3714065",
   "metadata": {},
   "source": [
    "## LLM Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8738ee87",
   "metadata": {},
   "source": [
    "## Language models probabilistic formulation\n",
    "\n",
    "Large language models are trained from discrete tokens. For ease of understanding equate roughly a token to a word. Say we have a super set of tokens $T = \\{t_1, t_2,...t_n\\}$ from which we create training dataset to train large language model. Here is a single record pair passed to train the model.\n",
    "\n",
    "$$\n",
    "x_1 = \\{t_1, t_2, t_3, t_4 \\}\n",
    "y_1 = \\{t_2, t_3, t_4, t_5 \\}\n",
    "$$\n",
    "\n",
    "The labels are created from x by sliding one step to the right. How much to slide is a design choice. Also the length of input is predefined, commonly known as context length. When we llama-2 has a context length of 4K, we know that each instance of its training record had 4K tokens. You should be quick to notice here that we don't need a separate label records or class information for each of our input. The output y values can be derived automatically from the input x. This makes creating a dataset for a language model much easier. We dont need separate time and resource to create a labelled dataset.\n",
    "\n",
    "If you have trouble with these notation, here is a python snippet where we represent token superset and training samples using words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d640aceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens superset \n",
      " ['on', 'deep', 'text', 'data.', 'trained', 'Large', 'amount', 'neural', 'models', 'language', 'are', 'network', 'of', 'vast']\n",
      "Training Instances\n",
      "X: ['on', 'deep', 'text'] y: ['deep', 'text', 'data.']\n",
      "X: ['deep', 'text', 'data.'] y: ['text', 'data.', 'trained']\n",
      "X: ['text', 'data.', 'trained'] y: ['data.', 'trained', 'Large']\n",
      "X: ['data.', 'trained', 'Large'] y: ['trained', 'Large', 'amount']\n",
      "X: ['trained', 'Large', 'amount'] y: ['Large', 'amount', 'neural']\n",
      "X: ['Large', 'amount', 'neural'] y: ['amount', 'neural', 'models']\n",
      "X: ['amount', 'neural', 'models'] y: ['neural', 'models', 'language']\n",
      "X: ['neural', 'models', 'language'] y: ['models', 'language', 'are']\n",
      "X: ['models', 'language', 'are'] y: ['language', 'are', 'network']\n",
      "X: ['language', 'are', 'network'] y: ['are', 'network', 'of']\n",
      "X: ['are', 'network', 'of'] y: ['network', 'of', 'vast']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"Large language models are deep neural network trained on vast amount of text data.\"\n",
    "T = list(set([x for x in text.split(\" \")]))\n",
    "\n",
    "print(f\"Tokens superset \\n {T}\")\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "k=3\n",
    "for i in range(len(T)-k):\n",
    "    X.append(T[i:i+k])\n",
    "    y.append(T[i+1:i+k+1])\n",
    "\n",
    "print(f\"Training Instances\")\n",
    "\n",
    "for x,y in zip(X,y):\n",
    "    print(f\"X: {x} y: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f40803",
   "metadata": {},
   "source": [
    "\n",
    "While we train the model, it learns to predict $t_5$ given ${t_1,t_2,t_3,t_4}$. To simply put it we are training the model to do next word prediction. These are called as autoregressive models or causal models. We train a model with $\\theta$ parameters. Our objective is to find the best parameters $\\theta$ so that *likelihood* of this model predicting the correct following token, given a bunch of tokens is very high. Remember these are probabilistic models. So the likelihood of a language model for given training example $(x_i, y_i)$ is the probability the model assings to the correct $y_i$. In our example\n",
    "\n",
    "\n",
    "$$\n",
    "x_1 = \\{t_1, t_2, t_3, t_4 \\}\n",
    "y_1 = \\{t_2, t_3, t_4, t_5 \\}\n",
    "$$\n",
    "\n",
    "We expect the model to assign high probability for $t_5$ given that our input to the model is $\\{t_1, t_2, t_3, t_4 \\}$.\n",
    "\n",
    "In simpler terms, let us say our superset of tokens is of length 5, with a context size of 2 and sliding of one, we want maximum probabilities for $t_3, t_4, t_5$ to be the next token prediction for their respective inputs.\n",
    "\n",
    "$$\n",
    "P(X, \\theta) = P(t_3 | t_2,t_1) * P(t_4|t_3,t_2) * P(t_5|t_4,t_3)\n",
    "$$\n",
    "\n",
    "Finally when the model is trained, we want the model to give maximum probabilities for $P(t_3 | t_2,t_1), P(t_4|t_3,t_2), P(t_5|t_4,t_3)$. Say if you encounter a scenario where\n",
    "\n",
    "$$\n",
    "P(t_3 | t_2,t_1) < P(t_4 | t_2,t_1)\n",
    "$$\n",
    "\n",
    "We know our model is not trained properly. Since each training pair is independent of the other, we can multiply their probabilities. Our aim in fitting a model is to arrive at best parameters $\\theta$ which can maximize these probability. \n",
    "\n",
    "All these probabilities are very small values. Mutliplying them will further reduce these values and may lead to numerical stability issues due to the limited precision of floating point numbers. For float32 datatype the smallest number is close to $10^-45$. We can leverage by moving to log scale. \n",
    "\n",
    "$$\n",
    "log(P(X, \\theta)) = log(P(t_3 | t_2,t_1)) + log(P(t_4|t_3,t_2)) + log(P(t_5|t_4,t_3))\n",
    "$$\n",
    "\n",
    "The below python snippet explains how we can move to log scale and still face no impediments in that process. The log functions are stricly monotonic in nature and hence they help us with the scale of our values and successfully address numerical instability issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eacba4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x777dbdd97b80>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD6CAYAAAC8sMwIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAq0klEQVR4nO3deXxU1f3/8dfJHpJAgCwsw05AVllmUERQQcS2Wre6ixYX3LEuXe33W7/ftmp/X7XValWqomxal6JUrdYFZUdCwg6yhC0ESMIWEsg65/fHmWwQJglzZ+4sn+fjkUfIzHDvxzG8c3LOveejtNYIIYQIXVF2FyCEEMI3EuRCCBHiJMiFECLESZALIUSIkyAXQogQJ0EuhBAhzpIgV0q9oZQqVEqtt+J4QgghWk5ZcR25UmocUArM1FoPbu71aWlpumfPnj6fVwghIsmqVauKtdbpJz8eY8XBtdYLlVI9W/r6nj17kp2dbcWphRAiYiildjX1uMyRCyFEiAtYkCulpiqlspVS2UVFRYE6rRBChL2ABbnWerrW2qm1dqannzLFI4QQ4gzJ1IoQQoQ4qy4/fBtYBvRXSuUrpe6w4rhCCCGaZ9VVKzdacRwhhBCtJ1MrQggR4iTIhQhD2TsP8fXmA3aXIQLEkqmVQFm6rZiN+0oA0Bo02vPZfA31j5nXNH6+4evRmtp7Wps6lsZ8oZs4DkBqm1h6pSXROz2J3mnJJMZFB+hdEOL0tNbMXLaL//14IzVuzR+vGszN5/SwuywBFJdW8MT8Dfzu8kGkp8RbeuyQCvJP1+9j9vLdlh5TKVCAUsrz2fM45glV9xpV91qAssqaRsfp0i6BXp5Q752eRO/0ZHqnJdElNZHoKIUQ/lZV4+aJ+RuYs2I3Fw/IxK01j88z2x9JmNsrr6iUn85YSeGxcm5wdY/sIH/8hwP5+aSzvIZv3Z9PCl/leaIumJVv4XqisoYdxWXkFZeyo6iMvOIy8opK+TB3L8cqquteFxcTRa+OZuRuRvCeoE9LIrVNnE81CFHryPFK7puTw9LtB7nngj78YlJ/qtxu7p2dI2Fus+ydh7hzZjbRSvH2XecyvHt7y88RUkGeGBdNIsExhZEYF83ALm0Z2KVto8e11hSXVpJXVEpecZkJ+6JSvt9/jC82HqDaXb9JWYekOHqn1Ya8Cfg+6Ul075BEXIwsX4iW2VZYyp1vraTgSDnPXns214x0ABAfFc3Lt4yQMLfRx2sLeOTdNThSE5kxxUWPjkl+OU9IBXkoUEqRnhJPeko85/Tu2Oi5qho3ew4dJ6/IM5IvLmN7URlfby6iuDS/7nVRCrp1aOMJ+eS60Xyf9GQyUuJ9/m1ChI+FW4q4f24O8TFRvD31HEb26NDo+fgYCXM7aK2ZvjCPp/69GVfP9kyf7KR9kv9+A5cgD6DY6ChPMCcDmY2eKymv8kzRlHqCvoy8ojKW5R2kvMpd97qkuOhGc/GXDOx0ym8FIvxprXlr6U7+9+ON9MtM4bXbnDjat2nytRLmgVVd4+aJf21g9vLdXDa0M89cezYJsf6dSbBkP/LWcjqdWraxbRm3W7OvpLyJkC9l75ETaA0TB2YybXwWQxzt7C5XBEBVjZvfzd/A3BW7mTgwk79cP4yk+ObHZBXVNdw7O4evNxfK1Sx+UlZRzYNv5/L15kLuvqA3v5x0FlEWXuyglFqltXae8rgEeeg6eryKN5fu5PXFeZSUVzPhrAymTcji7G6pdpcm/ORwmVnUXJZ3kHsv7MPPL+nfqqCQMPefwmPl3P7mSjYWlPC/VwzmlnOtf28lyMPYsfIq3lq6k9cW7+DI8Sou7J/OtAlZjPDD6riwz7bCUu54ayX7jpTz9DVDuHqE44yOI2Fuva0HjvHTGSs5fLySF28azvizMpv/S2dAgjwClFZUM3PZTv6+MI/Dx6sYm5XGQxOycPbs0PxfFkHt2y1FPOBZ1Hx18shTFjVbS8LcOku3F3P3rFUkxEbzxm0uv05xSpBHkLKKamYv38X0hXkcLKtkTN+OTBufdcpVNCL4aa15c+lOft+CRc3WkjD33bzcfH7x/lp6dkxixhSXZf9vTkeCPAIdr6xm7ordvPJtHsWlFZzbuwPTJmQxundHuYQxBFTVuPnvjzbw9ne7uWRgJn9u4aJma0iYnxmtNS9+vY1nv9jC6N4deWXySNolxvr9vBLkEay8qsYT6NspPFbBqJ4m0Mf0lUAPVofLKrl3ziqW5x3ivgv78FgrFzVbQ8K8dapq3Px23nr+kb2Hq4d35elrhgbsBj4JckF5VQ3/WLmHl7/Zzv6Sckb2aM+0CVmMy0qTQA8i2wqPccdb2T4varaGhHnLHCuv4r45OSzaWsy08X15eGK/gP7bkSAXdSqqa3g3O5+XF2yj4Gg5w7ql8tCELC7sny6BbrNvvi/kwbm5xMdG8epkJyN7BO7KIwlz7/YdPcGUGSvZVljKk1cN4TpXt4DXIEEuTlFRXcMHq/by0oJt7D1ygqGOdkwbn8WEARkS6AGmtWbGkp384ZON9O/Ultduc9I1NTHgdUiYN23TvhKmzFhJaUU1f7t5BOP62dNAXoJcnFZltZt5ufm8uGAbew6dYFCXtkybkMUlAzMl0AOgstrN7+av5+3v9vhtUbM1JMwbW7iliPvm5JAcH8OMKS4GdLZvSwwJctGsqho3H+bu5cUF29h18DgDOrdl2vi+TBrUyW8LbZHucFkl98xexYodh7j/oj48OtF/i5qtIWFuvLtyD7+et46sjGRmTHHRuV3gf0tqSIJctFh1jZv5awp48ett5BWX0T8zhQcn9OWHgzsHRciEi60HzKLm/pJy/nTNEK4a7v9FzdaI5DDXWvPcF1v469fbGJuVxt9uHkFKgv8vL2yOBLlotRq35uO1Bbzw1Va2F5WRlZHMA+P7ctnQLtL1yEcLvi9k2txc4mOjmX7ryKDdTiESw7yy2s0vP1jLvNy9XO/sxh+uGkxsdHD0B5AgF2esxq35dN0+/vr1VrYcKKV3ehIPju/L5UO7EBMk3+ChQmvNG0t28kebFzVbI5LC/OjxKu6enc3yvEM8dkk/7r+ob1CtE0mQC5+53ZrPNuznha+2snn/MXqlJXH/RX25cpgEektUVrv574/W887KPUwalMlz19m7qNkakRDm+YeP89MZK9l1sIz/95OhQTfVBRLkwkJut+Y/Gw/wwldb2bivBEf7RHql1bewathLtWFvVajtr9qwl6qn0XXtn2u/Pl2v1YbHO+nvxsVE0aNDG/qkJ9MnI5lu7ROD5gfMobJK7vUsaj5wUV8emdgv5NYbwjnM1+Uf5fa3VlJRVcOrk52M7hOc+xKdLshDYzgggkpUlOLSwZ2YNCiTLzcVMmv5Lo6VV1E7JtAAWqPNJzS6/jmN53Hd4Gt9ynPac6DaYYZu4ngNxyBaa8qr3Rwqq6x7LDZa0bOjaZFn+qGagO+dnkTbAC5cNVzU/Mv1w7hyeNeAndtK4dpp6KtNB3hgbi4dkuKYe+c5ZGWm2F1Sq8mIXISVoyeqyCsqZXtRGduLStleWMr2olJ2HTzeqPF1Rkq8J9hN27w+Gcn0SU+iS7tES0fKobKo2RrhNDKftXwXv/toPYO6tOP1nzrJSEmwuySvZEQuIkK7xFiGd2/P8JMCs6rGzW5P4+uGAT9/dQEl5dV1r0uIjWoU7LWj+d5pySTGtbzvotaa1xfv4MlPN3GWZ1GzS5AvarZUOIzM3W7Nnz7bzKsL85hwVgYv3Dg8ZNYrmiIjchHRtNYcLKv0BLsJ+doR/Z7DxxtN33RNTWwU8LUj+vTk+EZXNlRWu/mvD83ueJMGmTs128SFbkicTqiOzMuranj0vTV8snYft5zbnScuHxQ0aynNkRG5EE1QSpGWHE9acvwpjTfKq2rYebCM7YWeUbznY+WOQ5yoqql7XUp8DL0bBPy3W4r4LoQXNVsqFEfmh8squWtmNtm7DvPrH5zF1HG9g+rywjMlI3IhWsnt1uwvKa+fpqn9KCxjf0k5cTFR/N9PhnLFsNBc1GytUBmZ7zpYxpQZK8k/coLnrjuby4Z2sbukVpMRuRAWiYpSdElNpEtqIudnpTV6rrSimhq3Dki3mGAR7CPz6ho3q3Yd5r45OdRozdw7zwm7PrYS5EJYKDmEF8x8YUeYu91mfeNASTmFx8o5UFJBYUkFB46VU1hivj5QUk5xaQVuDd07tOHNKS56pyf7tS47WPJdp5S6FHgeiAZe01o/bcVxhRChw6ow11pz5HgVB47Vh3HDYD5wrILCknKKjlU0uqS0VsekODLaJpDZNp6BnduS2TaezHYJ/HBwZ9onxfn83xmMfA5ypVQ08BIwEcgHViql5mutN/p6bCFEaPEW5lprSsqrTwrlcgpLKupG1Ca0K6iscZ9y7NQ2sWSmJJDRNp6+6WkmoD2BbYI7gfTk+ID1zwwmVozIRwHbtNZ5AEqpd4ArAAlyISLQyWH+/qp8DnmmQMqrTg3olPgYMjyh7OrZwfw5JaEupDPbJpCeEk9CbMuv4480VgR5V2BPg6/zgXMsOK4QIkTVhvkT8zeyvaiUoY5UMlNMKGfUjaQTyEiJD+kbcYKFFe9gUxdhnjJxpZSaCkwF6N69uwWnFUIEs/iYaJ66eojdZUQEKyaT8oGG7aQdQMHJL9JaT9daO7XWzvR0exqXCiFEOLIiyFcCWUqpXkqpOOAGYL4FxxVCCNECPk+taK2rlVIPAJ9jLj98Q2u9wefKhBBCtIglqwxa60+BT604lhBCiNaJvAsuhRAizEiQCyFEiJMgFyIcFW6CPd/ZXYUIkNC6Er+sGMqPmj9rDdqNaeyoT/rsbuKxpl7X8LmWHIv655LTIWMQxITn3g0ihLlr4J2bobocHpEbrINGTRWsnguDroSEdpYeOrSCfMGTkP263VXUi46DzMHQZTh0HWE+p58FUXIrsbDRxo/g0Hbz56N7oV1k7Ise9Lb+B/41DZLS4awfWnro0AryYTdBt1GAAhUFtZ09lPI81uCzijr1sVOe4zSviWr67zX8fHQPFOSaj7Xv1v+AiW0Dnc82od7FE+4dekOUzGKJANAaFj0H8W2hogT2ZkuQB4ucWZDcCbIusfzQoRXkDqf5CAbdXDD4avNntxsOboOCHBPse3Mg+w2o/pt5Pr4ddBnWeOTerlv9DyIhrLLlcziwDi5/AT79OeSvhIFX2F2VKCmArZ/DmIcg2vrYDa0gD1ZRUZDez3ycfYN5rKYKijabUC/INSG/7EVwezq2t0mrD/XakXtKpn3/DSL0aQ2LnoHU7ua319zZkC8tFYPC6rlmvW34ZL8cXoLcX6JjodMQ8zHyNvNYVTkc2NB45L71C+r2GGvb1RPsnpF752HQJrxaUgk/2rnIjMB/9Kz5/nO4zJRfTZX5WtjD7TY/VHuOhY59/HIKCfJAik0Ax0jzUauiFPavbTxy3/xx/fPtezUeuXceCvEpga9dBL+Fz5g52GG3mK8dTlj+EhxYb75/hD12LYbDO+DCX/vtFBLkdotPhh7nmY9aJw5Dwer6kfvuFbD+A8+TCtL710/HDL4GkjraUbkIJvnZsONbuOQPZsAAZkRe+5wEuX1yZpl1soE/9tspJMiDUWJ76HOR+ahVWlg/HVOQC9u+gDVzza/OU/4tUzCRbuEz5vtm5JT6x9o5zAg9fyWMusu+2iLZicPmctARkyE20W+nkSAPFckZ0G+S+QCzsJW3AOZebz5u/RDikmwtUdhk/3rY8m+46HHzG14tpcz0Sv5K+2qLdOveh5oKGHGrX08jFzeHKqWgz3i45nVzrfC7t5lFLRF5Fj8HcSlNj7odLjiUB2UHA19XpNMaVr0FnYaae0v8SII81A38MfzoOTPV8tH9ZoVcRI6D22HDPHDdYaZWTlY7T75XLkMMuH2rzTX9fh6NgwR5eHBOgfG/hbX/gP887tkbRkSExc+ZrSJG39/0812GgYqW6RU75MyCmAQYcq3fTyVz5OFi7GNmU7HlfzN7OYx9xO6KhL8d2QNr3gHnHWYNpSlxSZA5SII80CqPw7r3zF21ial+P50EebhQCiY9ZcL8q/+BNh3rb0QS4WnpX83n8x70/jqHy+wH5K6RDd0CZdN8s9dNAKZVQKZWwktUFFz5MvSZAB//DDZ93OxfESGqtBBy3jJbQqR28/5ahwsqj0HxlsDUJiBnptksr8eYgJxOgjzcxMTB9bPMDUPv3w47F9tdkfCHZS9BTSWc34IptLobg2R6JSCKt8GuJWZflQBtjCdBHo7ikuDm96B9T3j7Rti/zu6KhJVOHIaVr8Ogq1q2d0fHPpCQKkEeKLmzzALzsJsCdkoJ8nDVpgNM/qfZl2XW1XBoh90VCausmG6mSloyGgfPjUEu2QkxEGq7APWbBCmdAnZaCfJw1s4Bk+eBuwpmXQXHDthdkfBVRSmseBn6/QA6DW7533O4TB/P8hL/1SZMF6CywoAtctaSIA936f3h5veh9ADMuaa+56kITatmmKmVcY+17u85nIA2G7EJ/8mZafa36TsxoKeVII8EDidcN8uMyN6+yeyLLkJPVbm55LDXBa3vlNXVs3WyzJP7T0mBGZEPu8kvXYC8kSCPFFkXw5WvmL2RP7gDaqrtrki01urZ5jer1o7GwdyUktZf5sn9qa4L0C0BP7UEeSQZei1c+ifTuOKTh+VW/lBSUwVLngfHKNNp5kw4XGZELv/fred2m6tV/NgFyBsJ8khz7j3mdv6cmfD17+2uRrTUuvfhyG4Y++iZX5vscMLxg6ZbjbDWrsVweGfAFzlryS36kWj8b6GsCBY9a/ZlOfdeuysS3rjdZnOszCH1+9GfiYYdgzr0tqY2YeTMNF2ABlxuy+llRB6JlILL/my+6T77ldmHQwSvTfPN7fVjH/HtTsGMARCbJAueVjtxGDbOh6HX+bULkDcS5JEqKhqufs3M6X14L2z90u6KRFO0Nr85dexrdtLzRVS0aeQtQW6tte95ugBNtq0ECfJIFpsAN8yFjIHw7mTYI//Ag862L2H/Wjj/YWt2LnS4zJYNVSd8P5YwP2hzZpoOQH7uAuSNBHmkS2gLt3wAyZkw91oo3Gx3RaKW1qapcrtuMPR6a47pcIG7GvatseZ4kS6AXYC8kSAXpinB5Hmm08zsq03DAmG/XUtgz3IY8xBEx1pzzNobiWR6xRo5M00XoME/sbUMn4JcKXWtUmqDUsqtlGrlrWYiqHToZUbmFcdMmEuzXvstfAaSMqy9wSQ5A1J7SJBbofK4uSx04JUB6QLkja8j8vXA1cBCC2oRdus0BG58Bw7vMtMsFaV2VxS59q6CvAVw3gPWXwkhOyFaY+NHni5A9i1y1vIpyLXWm7TW31tVjAgCPcfAtTOgINcsgFZX2l1RZFr0nNlD3Hm79cd2uKBkLxzda/2xI0mAuwB5E7A5cqXUVKVUtlIqu6ioKFCnFWfirB/B5S/A9q/hw3vMDSkicA5sNNsonHOP2U/earU3Bu2VUfkZK94Gu5cGtAuQN80GuVLqS6XU+iY+WnVRq9Z6utbaqbV2pqenn3nFIjBGTIaLn4D1H5ibhmR/jsBZ/BzEJcM5d/vn+J2GQHS8zJP7IndmwLsAedPsLfpa64sDUYgIQmN+BmXFsOxFSE6HcT+3u6Lwd3C7+eE5+gHT5ckfYuLMNc8yT35maqpg9dvQ79KAdgHyRi4/FKenFEz8PQy9Ab7+A2TPsLui8LfkeYiKhdH3+/c8DpdZB6mp8u95wtGWzz1dgOxf5Kzl6+WHVyml8oHRwCdKqc+tKUsEjagouOJFyLoEPnnErNQL/zi61+xpPWKy/0d6DidUl8OB9f49TzjKnWVLFyBvfL1qZZ7W2qG1jtdaZ2qtfdiaTQSt6Fi49i0zivvgTtghV5v6xdK/AtrcAORvDXdCFC1nYxcgb2RqRbRMXBtzjXmHPqZdXMFquysKL6VFsOpNcyt+anf/n6+dw4wqZcGzdVbPsa0LkDcS5KLl2nSAyf80d7HNvsYszAlrrHjZTHWc/3BgzqeUmV6RIG85txtyZ9vWBcgbCXLROm27mH1Z0DDrSijZZ3dFoe/EEfju72ab2rSswJ3X4YJDebIdQ0vtXGRrFyBvJMhF66Vlwc3vmQCYfY0JInHmVv7d3Oo99tHAnlduDGqd3FmQYF8XIG+CZ7ZehJauI+GG2TDnOnj7BnO5nIo2e2araHO1S1TMqY+paPN43WPRoKLM50avj2rwmpjGxwgnlWWw7G+QNQk6Dw3subsMM+9p/krfWshFguOHTBegEbfa1gXIGwlyceb6jIerp8MHd8DuZYE7b23Y1wW/5wdEYqq57n3AZYGrxVer3oQTh2DcY4E/d1wSZA6SefKWWFfbBSj4plVAglz4avDV0P1ccweorjELQroG3DWmgUHtn7Xb87nhcyc9pj2PNzzGyZ9Pecxdf549K+AfN8OoqSbQYxPsfne8q64wlxz2HAvdRtlTg8Nlera6a6zpQBSOGnUBCvBvTS0kQS5817aL+bBbdSV8+QQsf8n8hvCTNyGtr91Vnd7quXBsH1z5sn01OFyQ/bpp7pwxwL46gllBrrlx6kfP2l3JaYXZhKOIaDFxcOmT5nr3o/kw/QJY8w+7q2paTTUs+YtZa+h9oX111N0YJNMrp5U7C2ISbe8C5I0EuQg//X8A9yw2u/zNmwof3mcWFYPJ+g/MpWxjH7N3G9SOfcy+5xLkTass83QBusL2LkDeSJCL8NTOAbd9bHZsXD0Xpl8I+4NkXxG322xVmzHI7KBnJ6WkY5A3dV2AgnORs5YEuQhf0TEw/rdw60dQfhT+Ph5Wvm7/3urffwJFm2HsI8FxOaXDBYWboLzE7kqCT84ssy1Fj/PsrsSrIPguEsLPel8A9yyBnuebHRzfu82+m5i0Nk2VO/SGQVfZU8PJHE5AQ0GO3ZUEl+KtpgvQiODoAuSNBLmIDMnpcPP7cPH/wOZP4NWx9kwnbP8K9q02e6oEy+V+XUeazzJP3ljuLHN/wtnB0QXIGwlyETmiouD8n8GUz0ADb0yCJS8EtifpwmehrcM06wgWiamQ1l/myRuqqTJrK/0uhZRMu6tplgS5iDzdXHDPQnN1yxf/BXOvMzc0+duupeZX9THTzKWSwcThMiNyu9cPgsWWz6GsKOgXOWtJkIvIlNgerpsFP3zGNMp45XzYsci/51z0LLRJM53Xg43DCccPwuEddlcSHHJmeroAhUbLYglyEbmUglF3wZ1fmn1H3rocFjxpble3WkEubPvSbC4W18b64/tKOgbVKymAbV/A8JuDqguQNxLkQnQeClO/hbNvgG//ZAK9pMDacyx61myB6rrT2uNaJWMAxCbJgicEbRcgbyTIhQCIT4arXoErXzFt7F4eY+ZJrVC4GTb9C0bdDQltrTmm1aKioesICXK321w73nOsuUQ0REiQC9HQsBvh7m/NJmBzr4PPHzebcfli8Z/NaPfce62p0V8cLti/DqpO2F2JfXYugiO7YMRtdlfSKhLkQpwsLQvu/MpMgyx70VymeOgMFwEP7TB7WTunmJ6nwczhMlsC71tjdyX2yZnp6QIUQnvaI0EuRNNiE8y2pdfNNE2mXx0H6//Z+uMsed5MW4x+wPoareZwms+ROr1y/JCZAht6fVB2AfJGglwIbwZeAfcsgvT+8P4U+NdDLZ96KCkwC2fDb4G2nf1bpxWSMyC1R+QGeW0XoGC8PLQZEuRCNKd9D5jybxjzM9Oa7e/jzQJmc5a9ZC5lHPOQvyu0TqTuhFjXBWhY0HYB8kaCXIiWiI6Fif8DN38ApYVmW9ycWae/E7LsIGS/AUOuhfY9A1mpbxwuKNkLR/faXUlg1XYBGhF6o3GQIBeidbIuNk0rHE6Y/wD8866mt39d8bKZghn7SOBr9EXtjUF7I2xUnjMz6LsAeSNBLkRrte1s9ji/6HHT6Wf6BWZEV6v8KKyYDgMuN3ProaTTEIiOj6x58soy8/9x0JVB3QXIGwlyIc5EVDRc8Av46SdQVQ6vTYTlL5uplpWvQ8VRGPeY3VW2Xkyc6RYfSfPktV2AQnCRs5YEuRC+6HEe3LsE+k6Az34F79xkFjn7TjSBGIocLvMbRk2V3ZUERs7MkOgC5I0EuRC+atMBbnwHJj0FW7+A48Uw9lG7qzpzDidUl5vFv3BXvBV2LwuJLkDehMbWXkIEO6Vg9H3Qc4y5zb3HaLsrOnMNd0LsMtzeWvwtZ2bIdAHyRkbkQlip89khtWtek9o5zF7c4b7gWVMFa942DUZCoAuQNz4FuVLq/5RSm5VSa5VS85RSqRbVJYSwi1JmeiXcg3zLZ6YLUAgvctbydUT+BTBYaz0U2AL82veShBC2c7jgUJ65sSlc5cyElM4h0wXIG5+CXGv9H611tefL5YDD95KEELYL9xuDju41HZuG3RQyXYC8sXKO/Hbg3xYeTwhhly7DzCJguE6vrJ4bcl2AvGn2R5FS6kugUxNPPa61/sjzmseBamCOl+NMBaYCdO/e/YyKFUIESFwSZA4KzyB3uyE39LoAedNskGutvU4gKaVuAy4DJmh9uh2EQGs9HZgO4HQ6T/s6IUSQcLhg7btmB8eoaLursc7OhaYL0Pj/srsSy/h61cqlwC+BH2utj1tTkhAiKDhcUHkMirfYXYm1cmZCQqrZCydM+DpH/iKQAnyhlFqtlHrFgpqEEMGg7sagMJpeqesCdJ3pAhUmfFqu1Vr3taoQIUSQ6djHjFzzV8KIW+2uxhpr34WayvD57/GQOzuFEE2ruzEoTC5BbNgFqNMQu6uxlAS5EOL0HC4o3NR084xQU5ADhRvCbjQOEuRCCG8cTkCbEAx1ObNMF6AhodkFyBsJciHE6XUdaT6H+oJnZRmse990AUpoZ3c1lpMgF0KcXmJ7SOsX+vPkGz40l1KG4bQKSJALIZrjcJkR+env9wt+ubOgY1/oHsL7xHshQS6E8M7hhOMH4fAOuys5M3tXeboA3RrSXYC8kSAXQnjXsGNQKFrwJCR2AOftdlfiNxLkQgjv0gdAbFJoLnjuXmG2qx3zEMSn2F2N30iQCyG8i46BriNCM8i/eRLapMGou+yuxK8kyIUQzXM4TVPpqhN2V9JyO5dA3jdw/sNmW94wJkEuhGiewwXuati3xu5KWu6bpyA5M6znxmtJkAshmtfVaT6HyvTKjoWwcxGc/wjEtbG7Gr+TIBdCNC8lE1K7h0aQa22uVEnpDCN/anc1ASFBLoRoGYcrNC5BzFtgrhsf+2hY7TnujQS5EKJlHC4o2Ws60Aer2tF4W0fY3o7fFAlyIUTL1N4YtDeIR+XbvjTTP+Meg5h4u6sJGAlyIUTLdBoC0XHBO0+uNSz4o5nLH3az3dUElAS5EKJlYuKh89nBO0++5TMoyIVxv4CYOLurCSgJciFEyzlcJixrquyupLHa0Xj7XnD2DXZXE3AS5EKIlnM4obocDqy3u5LGNn9s7jy94JcQHWt3NQEnQS6EaLlg3AnR7YYFT0HHLBhyrd3V2EKCXAjRcu26mdvegynIN31kmipf+CuzwVcEkiAXQrScUvUdg4KBuwa+eRrSz4JBV9ldjW0kyIUQreNwwqHtcPyQ3ZXAhnlQtNmMxqOi7a7GNhLkQojWCZZ58ppqs8NhxiAYcIW9tdhMglwI0TpdhoOKsn96Zd17cHAbXPRriIrsKIvs/3ohROvFJUHmIHuDvKYKvv0TdBoKZ11mXx1BQoJcCNF6DpfpTu9223P+Ne/A4R1w0W/MAmyEkyAXQrSewwUVJVC8JfDnrq6Ehf/PTPH0uzTw5w9CEuRCiNarW/C0YXpl9Rw4shsuelxG4x4S5EKI1uvQBxJSAx/k1RWw8Bnzg6TvxYE9dxCTIBdCtF5UlLmePNCXIObMhJJ8mRs/iU9BrpT6vVJqrVJqtVLqP0qpLlYVJoQIcg4XFG6EimOBOV9VOSx6FrqPht4XBeacIcLXEfn/aa2Haq2HAR8D/+17SUKIkOBwAhr25gTmfKvehGP7ZDTeBJ+CXGtd0uDLJED7Vo4QImR0HWk+B2KevPI4LH4Oeo6FXuP8f74Q4/NWYUqpPwK3AkcB+X1HiEiR2B7S+gVmnjz7DSg9ANe+6f9zhaBmR+RKqS+VUuub+LgCQGv9uNa6GzAHeMDLcaYqpbKVUtlFRUXW/RcIIexTuxOi9uMv45VlsPjPZl68x3n+O08IazbItdYXa60HN/Hx0UkvnQtc4+U407XWTq21Mz093de6hRDBwOGE48VweKf/zvHd3805LvqN/84R4ny9aiWrwZc/Bjb7Vo4QIqT4eyfEimOw5HnoOxG6jfLPOcKAr1etPO2ZZlkLXAI8ZEFNQohQkT4AYpP8t+C54lU4ccjscChOy6fFTq31aadShBARIDoGuo7wT5CXH4Wlf4V+P6i/QkY0Se7sFEL4xuGE/Wuh6oS1x13+MpQfkdF4C0iQCyF843CBuxr2rbXumCcOw7KXzF7jnc+27rhhSoJcCOGbrk7z2crplWUvmW1yL5TReEtIkAshfJOSCandrQvy44fMtMrAK6HTYGuOGeYkyIUQvnO4rLsEcekL5iagC39lzfEigAS5EMJ3DpfZXrakwLfjlBbBiukw+BrIGGBNbRFAglwI4Turbgxa+jxUn4ALful7TRFEglwI4btOQyA6zrd58mMH4LvXYMh1kN7PutoigAS5EMJ3MfHmMkFfRuRL/gI1lXDBLywrK1JIkAshrOFwQUEu1FS1/u+W7IOVr8OwG6FjH+trC3MS5EIIazicZn77wIbW/93Fz4GugXE/t76uCCBBLoSwRt2CZyvnyY/mmzZuw2+B9j2trioiSJALIazRrhskZ7Z+nnzRs6YxxdjH/FNXBJAgF0JYQ6n6jkEtdXgX5MyCkbdBajf/1RbmJMiFENZxOOHQdnObfUssegZUFJz/iH/rCnMS5EII67TmxqBDeZA7B5xToF1X/9YV5iTIhRDW6TLcjLBbMr2y8BmIjoXzH/Z/XWFOglwIYZ24JMgc1HyQH9wOa94G152Q0ikwtYUxCXIhhLUcLti7Ctzu07/mm6chJgHGSJtfK0iQCyGs5XCZphDFW5p+vuh7WPcejLoLkjMCW1uYkiAXQliruRuDvnnaTMGcJ6Nxq0iQCyGs1aEPJKQ2HeQHNsCGeXDO3ZDUMeClhSsJciGEtaKizPXkTV2C+M3TEJcMox8IfF1hTIJcCGE9hwsKN0LFsfrH9q2FTfNh9H3QpoN9tYUhCXIhhPUcTkDD3pz6x755GhLawbn32VZWuJIgF0JYr+tI87l2nrwgF77/BEY/CImptpUVriTIhRDWS2wPaf3q58kXPGUeO+due+sKUxLkQgj/qN0JMT8btn4O502DhLZ2VxWWJMiFEP7hcMLxYpg/Ddp0hFFT7a4obEmQCyH8o/bGoMINMOZnEJ9saznhLMbuAoQQYSp9AMQmmbs4XXfaXU1YkyAXQvhHdAxM+gO0dUBcG7urCWsS5EII/3HebncFEUHmyIUQIsRZEuRKqceUUloplWbF8YQQQrScz0GulOoGTAR2+16OEEKI1rJiRP5n4BeAtuBYQgghWsmnIFdK/RjYq7Ve04LXTlVKZSulsouKinw5rRBCiAaavWpFKfUl0FR31MeB3wCXtOREWuvpwHQAp9Mpo3chhLBIs0Gutb64qceVUkOAXsAapRSAA8hRSo3SWu+3tEohhBCndcbXkWut1wF1nVOVUjsBp9a62IK6hBBCtJDS2ppZjtYEuVKqCNh1hqdKA+SHRT15P+rJe9GYvB+NhcP70UNrnX7yg5YFeaAopbK11k676wgW8n7Uk/eiMXk/Ggvn90Pu7BRCiBAnQS6EECEuFIN8ut0FBBl5P+rJe9GYvB+Nhe37EXJz5EIIIRoLxRG5EEKIBkIqyJVSlyqlvldKbVNK/crueuyilOqmlFqglNqklNqglHrI7pqCgVIqWimVq5T62O5a7KaUSlVKva+U2uz5Phltd012UUo97Pl3sl4p9bZSKsHumqwWMkGulIoGXgJ+AAwEblRKDbS3KttUA49qrQcA5wL3R/B70dBDwCa7iwgSzwOfaa3PAs4mQt8XpVRXYBrmHpfBQDRwg71VWS9kghwYBWzTWudprSuBd4ArbK7JFlrrfVrrHM+fj2H+kXa1typ7KaUcwI+A1+yuxW5KqbbAOOB1AK11pdb6iK1F2SsGSFRKxQBtgAKb67FcKAV5V2BPg6/zifDwAlBK9QSGAytsLsVuf8Fsp+y2uY5g0BsoAmZ4pppeU0ol2V2UHbTWe4FnMP0S9gFHtdb/sbcq64VSkKsmHovoS26UUsnAB8DPtNYldtdjF6XUZUCh1nqV3bUEiRhgBPCy1no4UAZE5JqSUqo95jf3XkAXIEkpdYu9VVkvlII8H+jW4GsHYfgrUksppWIxIT5Ha/1Pu+ux2Rjgx579ft4BxiulZttbkq3ygXytde1vae9jgj0SXQzs0FoXaa2rgH8C59lck+VCKchXAllKqV5KqTjMgsV8m2uyhTL7Br8ObNJaP2d3PXbTWv9aa+3QWvfEfF98rbUOu1FXS3m2kd6jlOrveWgCsNHGkuy0GzhXKdXG8+9mAmG48HvG29gGmta6Win1APA5ZuX5Da31BpvLsssYYDKwTim12vPYb7TWn9pXkggyDwJzPIOePGCKzfXYQmu9Qin1PpCDudorlzC8w1Pu7BRCiBAXSlMrQgghmiBBLoQQIU6CXAghQpwEuRBChDgJciGECHES5EIIEeIkyIUQIsRJkAshRIj7/9aJpoNdGHj7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fx = lambda x: np.sin(x)\n",
    "lfx = lambda x: np.log(np.sin(x))\n",
    "\n",
    "x = np.random.random(10)\n",
    "\n",
    "\n",
    "plt.plot(fx(x))\n",
    "plt.plot(lfx(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19698be7",
   "metadata": {},
   "source": [
    "Logarithms are *stricly monatonic*. They change the values, but not does not changes the shape, you see that peaks and valleys are same for both the functions in the above example. fx and lfx are two functions, where the second is a log of values thrown by the first function. Coming back to our equation, we can write the log likelihood in a generic way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefda8c8",
   "metadata": {},
   "source": [
    "For super set of tokens $T = \\{t_1, t_2,...t_n\\}$, say context length is k, we can write above equation as\n",
    "\n",
    "$\n",
    "log(P(X,\\theta)) = \\sum_{i=1}^n log(P(t_i+k|t_i-k,..t_i+1,t_i))\n",
    "$\n",
    "\n",
    "As said earlier our objective is to build a model, which has the right parameters $\\theta$, such that the output probabilities of correct output token is maximum. In other words, we want our $\\theta$ such that value of the above equation is at the highest. To further iron it out, say we have two models, the first model has parameters $\\theta_1$ and the second model has parameters $\\theta_2$ if\n",
    "\n",
    "$\n",
    "log(P(X,\\theta_1)) >> log(P(X,\\theta_2))\n",
    "$\n",
    "\n",
    "we can conclude that our second model is superior to our first model. We say that we want to maximize the log-likelihood equation. The figure below shows the a sample input and corresponding output produced by the model.\n",
    "\n",
    "```{figure} ../images/llm_io.jpg\n",
    "---\n",
    "height: 150px\n",
    "name: llm-io-fig\n",
    "---\n",
    "Input and output to a language model\n",
    "```\n",
    "\n",
    "For illustration we have assumed context length as two. So for token 1 and token 2, the model predicts a distribution over all the tokens in the superset. For token 1, you can see that we have logits values for all the tokens $t_1 to t_5$. These values dont sum up to one, they can be passed to a softmax normalization later to be normalized. We expect that when the model is trained, for token $t_1$, the model should assign high logit value to $t_2$ and similarly for $t_2$ high logit values for $t_3$. Say we have n pairs of training data. We can rewrite our objective equation as\n",
    "\n",
    "$$\n",
    "log(P(X, \\theta)) = \\frac{1}{n}.\\sum_{i=1}^n p_i^{True}.log(p_i)\n",
    "$$\n",
    "\n",
    "See the python code here for token $t_2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a697dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.789"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [0.,0.,1.,0.,0.]\n",
    "y_predicted = [.23,.002,.789,.654,.567]\n",
    "\n",
    "sum([x*y for x,y in zip(y_true, y_predicted)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc7d80",
   "metadata": {},
   "source": [
    "Since its a standard for optimizers to use the minimize operation, we we take the negative of our objective function.\n",
    "\n",
    "$$\n",
    "NLL = -\\frac{1}{n}.\\sum_{i=1}^n p_i^{True}.log(p_i)\n",
    "$$\n",
    "\n",
    "This is the negative log-\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766faee2",
   "metadata": {},
   "source": [
    "For those new to LLMs, we will run ollama service to play with some popular large language models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c65c0-3022-40c5-8803-26ed1f3acee1",
   "metadata": {},
   "source": [
    "## Ollama\n",
    "\n",
    "Ollama enables us to run open source LLMs locally. A tool that enables local deployment of large language models. A great tool for experimetning with LLMs. No need cloud hosting.\n",
    "http://github.com/ollama/ollama. Refer to the website for installation.\n",
    "\n",
    "Advantages for using Ollama,\n",
    "\n",
    "1. Quick iteratvie development without needing to deploy model changes\n",
    "2. Privacy and security - data does not leave your machine.\n",
    "3. cost - more cost effective than making API calls.\n",
    "4. control - more control over the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e80020-d6e3-41c0-b8c4-7a1a7cf84bfc",
   "metadata": {},
   "source": [
    "    curl  -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "    >>> Installing ollama to /usr/local/bin...\n",
    "    >>> Creating ollama user...\n",
    "    >>> Adding ollama user to render group...\n",
    "    >>> Adding ollama user to video group...\n",
    "    >>> Adding current user to ollama group...\n",
    "    >>> Creating ollama systemd service...\n",
    "    >>> Enabling and starting ollama service...\n",
    "    Created symlink /etc/systemd/system/default.target.wants/ollama.service → /etc/systemd/system/ollama.service.\n",
    "    >>> NVIDIA GPU installed.\n",
    "\n",
    "    sudo systemctl status ollama\n",
    "    ● ollama.service - Ollama Service\n",
    "         Loaded: loaded (/etc/systemd/system/ollama.service; enabled; vendor preset: enabled)\n",
    "         Active: active (running) since Sat 2024-05-11 19:59:42 EDT; 5min ago\n",
    "       Main PID: 1053781 (ollama)\n",
    "          Tasks: 18 (limit: 18827)\n",
    "         Memory: 480.5M\n",
    "         CGroup: /system.slice/ollama.service\n",
    "                 └─1053781 /usr/local/bin/ollama serve\n",
    "    \n",
    "    May 11 19:59:42 gopi-G5-MD ollama[1053781]: Couldn't find '/usr/share/ollama/.ollama/id_ed25519'. Generating new private key.\n",
    "    May 11 19:59:42 gopi-G5-MD ollama[1053781]: Your new public key is:\n",
    "    May 11 19:59:42 gopi-G5-MD ollama[1053781]: ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIPkwrlZDwOjnkF2xAiAWVxs8CrIfsqSnNcs3adQQv9xC\n",
    "    May 11 19:59:42 gopi-G5-MD ollama[1053781]: 2024/05/11 19:59:42 routes.go:1006: INFO server config env=\"map[OLLAMA_DEBUG:false OLLAMA_LLM_LIBRARY: OLLAMA_MAX_LOADED_MODELS:1 OLLAMA_MAX_QUEUE:512 OLLAMA_>\n",
    "    May 11 19:59:42 gopi-G5-MD ollama[1053781]: time=2024-05-11T19:59:42.753-04:00 level=INFO source=images.go:704 msg=\"total blobs: 0\"\n",
    "    May 11 19:59:42 gopi-G5-MD ollama[1053781]: time=2024-05-11T19:59:42.753-04:00 level=INFO source=images.go:711 msg=\"total unused blobs removed: 0\"\n",
    "    May 11 19:59:42 gopi-G5-MD ollama[1053781]: time=2024-05-11T19:59:42.753-04:00 level=INFO source=routes.go:1052 msg=\"Listening on 127.0.0.1:11434 (version 0.1.36)\"\n",
    "    May 11 19:59:42 gopi-G5-MD ollama[1053781]: time=2024-05-11T19:59:42.753-04:00 level=INFO source=payload.go:30 msg=\"extracting embedded files\" dir=/tmp/ollama769771873/runners\n",
    "    May 11 19:59:44 gopi-G5-MD ollama[1053781]: time=2024-05-11T19:59:44.699-04:00 level=INFO source=payload.go:44 msg=\"Dynamic LLM libraries [cpu cpu_avx cpu_avx2 cuda_v11 rocm_v60002]\"\n",
    "    May 11 19:59:45 gopi-G5-MD ollama[1053781]: time=2024-05-11T19:59:45.929-04:00 level=INFO source=types.go:71 msg=\"inference compute\" id=0 library=cpu compute=\"\" driver=0.0 name=\"\" total=\"15.4 GiB\" avail>\n",
    "    lines 1-19/19 (END)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be934afd-2196-473d-ba30-8012c07329f4",
   "metadata": {},
   "source": [
    "## List of available models\n",
    "\n",
    "    ollama list\n",
    "    NAME\tID\tSIZE\tMODIFIED \n",
    "\n",
    "## Pull a model\n",
    "\n",
    "     ollama pull phi3\n",
    "    pulling manifest \n",
    "    pulling 4fed7364ee3e... 100% ▕███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏ 2.3 GB                         \n",
    "    pulling c608dc615584... 100% ▕███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  149 B                         \n",
    "    pulling fa8235e5b48f... 100% ▕███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏ 1.1 KB                         \n",
    "    pulling d47ab88b61ba... 100% ▕███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  140 B                         \n",
    "    pulling f7eda1da5a81... 100% ▕███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  485 B                         \n",
    "    verifying sha256 digest \n",
    "    writing manifest \n",
    "    removing any unused layers \n",
    "    success \n",
    "\n",
    "\n",
    "    (base) gopi@gopi-G5-MD:~/Documents/small_llm$ ollama list\n",
    "    NAME       \tID          \tSIZE  \tMODIFIED       \n",
    "    phi3:latest\ta2c89ceaed85\t2.3 GB\t19 seconds ago\t\n",
    "\n",
    "\n",
    "Now listing the model shows phi3 model. The models are stored as blob in /usr/share/ollama/.ollama\n",
    "\n",
    "Ollama bundles the model into a single package defined by a Modelfile. Let us see the modelfile for phi3.\n",
    "\n",
    "    >>> /show modelfile\n",
    "    # Modelfile generate by \"ollama show\"\n",
    "    # To build a new Modelfile based on this, replace FROM with:\n",
    "    # FROM phi3:latest\n",
    "    \n",
    "    FROM /usr/share/ollama/.ollama/models/blobs/sha256-4fed7364ee3e0c7cb4fe0880148bfdfcd1b630981efa0802a6b62ee52e7da97e\n",
    "    TEMPLATE \"{{ if .System }}<|system|>\n",
    "    {{ .System }}<|end|>\n",
    "    {{ end }}{{ if .Prompt }}<|user|>\n",
    "    {{ .Prompt }}<|end|>\n",
    "    {{ end }}<|assistant|>\n",
    "    {{ .Response }}<|end|>\n",
    "    \"\n",
    "    PARAMETER stop <|user|>\n",
    "    PARAMETER stop <|assistant|>\n",
    "    PARAMETER stop <|system|>\n",
    "    PARAMETER stop <|end|>\n",
    "    PARAMETER stop <|endoftext|>\n",
    "    PARAMETER num_keep 4\n",
    "    LICENSE \"\"\"Microsoft.\n",
    "    Copyright (c) Microsoft Corporation.\n",
    "    \n",
    "    MIT License\n",
    "    \n",
    "    Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "    of this software and associated documentation files (the \"Software\"), to deal\n",
    "    in the Software without restriction, including without limitation the rights\n",
    "    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "    copies of the Software, and to permit persons to whom the Software is\n",
    "    furnished to do so, subject to the following conditions:\n",
    "    \n",
    "    The above copyright notice and this permission notice shall be included in all\n",
    "    copies or substantial portions of the Software.\n",
    "    \n",
    "    THE SOFTWARE IS PROVIDED *AS IS*, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "    SOFTWARE.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c45969-764a-497f-b218-4d0f94b0175b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Interacting with LLM\n",
    "\n",
    "    ollama run phi3:latest\n",
    "    >>> Why is the sky blue in color?\n",
    "     The sky appears blue to our eyes because of a phenomenon called Rayleigh scattering. As sunlight travels through Earth's atmosphere, it encounters molecules and small particles that are much \n",
    "    smaller than its wavelength. These particles scatter shorter-wavelength light (blue and violet) more effectively than longer-wavelength light (red, orange).\n",
    "    \n",
    "    However, our eyes are less sensitive to violet light, and the Sun emits less violet light compared to blue light; that's why we see a predominantly blue sky during daytime. At sunrise or sunset, \n",
    "    when the light path through the atmosphere is longer, even more scattering of red and orange wavelengths occurs, which makes the sky appear in shades of red, pink, and orange.\n",
    "    \n",
    "    The overall color perception can also be affected by atmospheric conditions such as pollution or dust particles. But under normal circumstances on a clear day, Rayleigh scattering is responsible \n",
    "    for the blue coloration of our sky.\n",
    "    \n",
    "    >>> Send a message (/? for help)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d6f04c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
